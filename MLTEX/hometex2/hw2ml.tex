\documentclass[a4paper,12pt]{article}


\usepackage{setspace}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{float}
\usepackage{titlesec}
\usepackage{subfigure}
\usepackage{caption}
\captionsetup{figurewithin=section}
\usepackage{amsmath}


\begin{document}

\title{\textbf{Homework 2}}
\author{Yunian Pan}
\maketitle{}

\section{Problem 1: Backpropagation}

\subsection{case 1}

Sol: 

Given $x_i = g(y_j) = \dfrac{1}{1+e^{-\sum_j {w_{ji}y_j}}}$, and $\sum_{i}\dfrac{\partial E}{\partial x_i} = -\sum_i {(\dfrac{t_i}{x_i} - \dfrac{1 - t_i}{1 - x_i})}$ apply the chain rule, first take $x_i$ and $y_j$ as fixed to compute the gradient for $w_{ji}$, then take $z_k$ and $y_j$ as fixed to compute the gradient for $w_{kj}$ we have 
\begin{align}
\frac{\partial E}{\partial w_{ji}} & = \frac{\partial E}{\partial x_i}\frac{\partial x_i}{\partial w_{ji}}\nonumber \\
&= (\frac{1-t_i}{1- x_i} - \frac{t_i}{x_i})\frac{\partial g(w_{ji}, y_j) }{\partial w_{ji}} \nonumber \\
& = (\frac{1-t_i}{1- x_i} - \frac{t_i}{x_i}) x^2_i y_{j} e^{-\sum_j{w_{ji}y_j}} \nonumber \\
& = (\frac{1-t_i}{1- x_i} - \frac{t_i}{x_i}) x_i y_{j} (1-x_i) \nonumber \\
& = (x_i - t_i) y_j \nonumber \\
\qquad \nonumber 
\end{align}

\begin{align}
\frac{\partial E}{\partial w_{kj}} & =  \sum_{i} (\frac{\partial E}{\partial x_i}  \dfrac{\partial x_i}{\partial y_j} )\frac{\partial y_j}{\partial w_{kj}} \nonumber \\
& =  \sum_{i} \frac{\partial E}{\partial x_i}(-w_{ji}) x_i (1 - x_i) (-z_k) y_j(1- y_j)\nonumber  \\
& = \sum_{i} \frac{x_i - x_i t_i - t_i + x_i t_i}{ (1-x_i)x_i } (-(-w_{ji}) x_i (1 - x_i))(- (-z_k) y_j(1- y_j)) \nonumber \\
& = \sum_{i} (x_i - t_i) w_{ji} y_j(1- y_j) z_k \nonumber 
\end{align}

Thus, we have\qquad $\sum_{i} \dfrac{\partial E}{\partial w_{ji}} = \sum_i \delta_j^i y_j$, \qquad $\sum_{j} \dfrac{\partial E}{\partial w_{kj}} = \sum_j \delta_k^j z_k$. 

\subsection{case 2}

Sol:

Given the cross-entropy $E = -\sum_i t_i \log(x_i)$ and softmax activation function $x_i = \dfrac{e^{\sum_{j} w_{ji} y_j}}{\sum_{i} e^{\sum_{j} w_{ji}y_j}} = f(w_{11}, \ldots , w_{j1}, \ldots, w_{ji}, \ldots,  w_{jm}, \ldots , y_j, \ldots)$, we have
\begin{align}
\frac{\partial E}{\partial x_i} &= - \frac{t_i}{x_i} \nonumber \\
\quad  \nonumber \\
\frac{\partial x_m}{\partial w_{ji}} & =  \frac{y_j(\delta(i-m) e^{\sum_{j}w_{jm}y_j}( \sum_{i}e^{\sum_{j}w_{ji}y_j} ) - e^{\sum_{j}w_{jm}y_j} e^{\sum_{j}w_{ji}y_j})}{(\sum_{i} e^{\sum_{j} w_{ji}y_j})^2}   \nonumber  \\
& = y_j x_m( \delta(i-m) - x_i)  \nonumber \\
\nonumber \\
\frac{\partial E}{\partial w_{ji}} & = \sum_{m} \frac{\partial E}{\partial x_m} \frac{\partial x_m}{\partial w_{ji}}   \nonumber \\
& = \sum_{m} y_j (-\frac{t_m}{x_m}) x_m( \delta(i - m) - x_i)  \nonumber \\
& = y_j (\sum_{m} t_m \cdot x_i - t_i) \nonumber 
\end{align}
\begin{align}
\frac{\partial E}{\partial w_{kj}} & = \sum_{i}( \sum_{m} (\frac{\partial E}{\partial x_m} \frac{\partial x_m}{\partial y_j}) \frac{\partial y_j}{\partial w_{kj}} ) \nonumber \\
& = \sum_{i} (w_{ji} (\sum_{m} t_m x_i - t_i)) y_j (1 - y_j) z_k \nonumber \\
& =  \sum_{i}(\sum_{m} t_m x_i - t_i)(w_{ji} y_j(1- y_j)) z_k \nonumber
\end{align}
Here\quad$\delta_j^i = \sum_{m} t_m \cdot x_i - t_i$,\quad$\delta_k^j =  \sum_{i}(\sum_{m} t_m x_i - t_i)(w_{ji} y_j(1- y_j))$. 


\end{document}