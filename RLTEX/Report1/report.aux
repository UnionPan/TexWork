\relax 
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Theoretical development}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-A}}Stochastic Optimal Control Definition and Notation}{1}}
\newlabel{cost}{{1}{2}}
\newlabel{valuefunc}{{2}{2}}
\newlabel{dynamicfunc}{{3}{2}}
\newlabel{immediate cost}{{4}{2}}
\newlabel{HJB}{{5}{2}}
\newlabel{optimal control}{{6}{2}}
\newlabel{nonlinear PDE}{{7}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-B}}Transformation of HJB into a Linear PDE}{2}}
\newlabel{nonlinear PDE2}{{8}{3}}
\newlabel{gamma1}{{9}{3}}
\newlabel{assumption1}{{10}{3}}
\newlabel{reduced form1}{{11}{3}}
\newlabel{solution1}{{13}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-C}}Generalized Path Integral Formulation}{3}}
\newlabel{discretized form}{{14}{4}}
\newlabel{factorized transition probabilities}{{15}{4}}
\newlabel{transition dynamic}{{16}{4}}
\newlabel{transition directly}{{17}{4}}
\newlabel{transition directly}{{18}{4}}
\newlabel{transition directly}{{19}{4}}
\newlabel{solution2}{{20}{4}}
\newlabel{solution3}{{20}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-D}}Optimal Controls}{5}}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces }}{6}}
\newlabel{table 1}{{I}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-E}}Special Cases}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {II-E}1}systems with one dimensional directly actuated states}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {II-E}2}systems with one dimensional directly actuated states}{6}}
\newlabel{21}{{29}{6}}
\newlabel{22}{{30}{6}}
\newlabel{23}{{31}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {II-E}3}systems with one dimensional directly actuated states}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Reinforcement Learning with Parameterized Polices}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-A}}Parameterized Policies}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-B}}From DMPs to PI$^2$}{7}}
\newlabel{DMPs}{{36}{7}}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces }}{9}}
\newlabel{table 2}{{II}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Evaluations}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}}brief introduction of some related works}{10}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}1}Stochastic optimal control and path integrals}{10}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}2}REINFORCE}{10}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}3}GPOMDP and The Policy gradient theorem algorithm}{10}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}4}the episodic natural actor critic}{10}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}5}PoWER}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}}Learning Tasks}{10}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}1}Learning Optimal Performance of a 1 DOF Reaching Task}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces 1 DOF comparison}}{11}}
\newlabel{1dof}{{1}{11}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}2}Learning Optimal Performance of a 1 DOF Via-Point Task}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces 1 DOF via-point comparison}}{11}}
\newlabel{1dofv}{{2}{11}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}3}Learning Optimal Performance of a Multi-DOF Via-Point Task}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces multi-DOF via-point comparison}}{11}}
\newlabel{mdofv}{{3}{11}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}4}Dog jumping}{12}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Conclusion}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-A}}The Simplification $\lambda R^{-1} = \Sigma _{\epsilon }$}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-B}}Model-based, Hybrid, and Model-free Learning}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces learning curve}}{12}}
\newlabel{dog}{{4}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-C}}Rules of Cost Function Design}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-D}}Dealing with Hidden State}{12}}
\bibcite{Theodo}{1}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-E}}Arbitrary States in the Cost Function}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-F}}*Discussion}{13}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {V-F}1}Feynman-Kac lemma}{13}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {V-F}2}Eular scheme and Ito's lemma}{13}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {V-F}3}Fisher information matrix}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-G}}Final conclusion}{13}}
\@writefile{toc}{\contentsline {section}{References}{13}}
